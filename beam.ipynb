{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1JZNR-GoAGIyUiu3_xfSdIMI3oAq91vYH","authorship_tag":"ABX9TyOyLt04/Cvm0pSs6bJKw6za"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import sys\n","import pickle\n","import numpy as np\n","import pandas as pd\n","\n","#sys.path.append('/content/drive/MyDrive/Project_2')\n","\n","##########################################################################################\n","\n","# loading variables required\n","embedding_matrix = pickle.load(open('C:/Users/rpris/OneDrive/Desktop/Project_2/embedding_matrix.pkl','rb'))\n","embedding_matrix_per = pickle.load(open('C:/Users/rpris/OneDrive/Desktop/Project_2/embedding_matrix_per.pkl','rb'))\n","\n","token_perturbation = pickle.load(open(\"C:/Users/rpris/OneDrive/Desktop/Project_2/token_perturbation-reg.pkl\",'rb'))\n","token_correct = pickle.load(open(\"C:/Users/rpris/OneDrive/Desktop/Project_2/token_correct-reg.pkl\", 'rb'))\n","\n","v_perturbation = len(token_perturbation.word_index.keys()) +1\n","v_correct=len(token_correct.word_index.keys())  + 1    \n","\n","##########################################################################################\n","\n","# importing our custom attention_model library\n","\n","import monotonic_attention\n","\n","##########################################################################################\n","\n","#defining model\n","e_vocab_size = v_perturbation\n","d_vocab_size = v_correct\n","embedding_dim_e = 300\n","embedding_dim_d = 300\n","i_length = 16\n","o_length = 16\n","enc_units = 300\n","dec_units = 300\n","score_fun = 'parallel'\n","att_units = 300\n","\n","attention = monotonic_attention.attention_model(e_vocab_size, d_vocab_size, embedding_dim_e,embedding_dim_d, \n","        i_length, o_length, enc_units, dec_units ,score_fun ,att_units, embedding_matrix, embedding_matrix_per)\n","\n","\n","attention.build((None,512,16))    \n","\n","attention.load_weights(\"C:/Users/rpris/OneDrive/Desktop/Project_2/wts/attention/weights-21-0.2798.hdf5\")\n","\n","##########################################################################################\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["encoder = attention.layers[0]\n","decoder_layer = attention.layers[1]\n","onestep = decoder_layer.layers[0]\n","\n","def beam(enc_inp):\n","    #inference\n","\n","    e_input=[]\n","    for i in enc_inp.split():\n","        if token_perturbation.word_index.get(i) == None:\n","            e_input.append(0)\n","        else:\n","            e_input.append(token_perturbation.word_index.get(i))\n","\n","    e_input = tf.keras.preprocessing.sequence.pad_sequences([e_input], maxlen=16, padding='post')\n","\n","\n","    e_output, e_hidden, e_cell = encoder(e_input,0)\n","\n","    d_hidden = e_hidden\n","    d_cell = e_cell                   #final encoder state is equal to initial decoder state\n","\n","    #initial decoder input is start\n","    d_input = tf.expand_dims([token_correct.word_index['<start>']],0)\n","    attention_weights = np.zeros((1,16), dtype='float32')\n","    attention_weights[:,0] = 1\n","\n","    predicted, d_hidden, d_cell, attention_weights, context_vector = onestep(d_input, e_output, d_hidden, d_cell, attention_weights)\n","    topk = tf.math.top_k(predicted[0], k=3)\n","    top3_index = topk.indices.numpy()\n","    top3_prob = topk.values.numpy()\n","\n","    prev_index = []\n","    for i in top3_index:\n","        prev_index.append([int(i)])\n","\n","\n","    for word in range(1,16):\n","        product = []\n","        for i in range(3):\n","            d_input = tf.expand_dims([top3_index[i]],0)\n","            \n","            predicted, dh, dc, aw, context_vector = onestep(d_input, e_output, d_hidden,                                                                                     d_cell, attention_weights)\n","            predicted = np.array(predicted[0])\n","        \n","            product.append(predicted + top3_prob[i])\n","    \n","        #restoring hidden states and weights (of the previous input ) for the next iteration\n","        d_input = tf.expand_dims([top3_index[0]],0)   \n","        predicted, d_hidden, d_cell, attention_weights, context_vector = onestep(d_input, e_output, d_hidden,                                                                                     d_cell, attention_weights)\n","        # getting the conditional probability\n","        product = np.stack(product, axis=0).reshape(-1,)\n","        \n","        #getting top 3\n","        topk = tf.math.top_k(product, k=3)\n","        top3_index_temp = topk.indices.numpy()\n","        top3_prob  = topk.values.numpy()\n","    \n","        top3_index = []    \n","        temp = []\n","        \n","        #getting the absolute index since we stacked all the three outputs together above\n","        for i in top3_index_temp:\n","\n","            if i>28466 and i<=56933: \n","                top3_index.append(i-28467)           #2nd group\n","                tmp = prev_index[1].copy()         # tmp = prev_index[1]--> this was changing the original list \n","                tmp.append(i-28467)\n","                \n","            elif i>56933:\n","                top3_index.append(i - 56934)         #3rd group\n","                tmp = prev_index[2].copy()              \n","                tmp.append(i-56934)\n","                \n","            else: \n","                top3_index.append(i)                 #1st group\n","                tmp = prev_index[0].copy()\n","                tmp.append(i)\n","\n","            temp.append(tmp)\n","    \n","        prev_index = temp\n","    \n","    try:\n","        xx = prev_index[0][:prev_index[0].index(18896)]\n","    except:\n","        xx = prev_index[0]\n","\n","    \n","    translation = \"\"\n","    for i in xx:\n","        translation = translation + token_correct.index_word[i] + ' '\n","    \n","    return translation"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def inference_att(enc_inp):\n","\n","    translation=\"\"\n","    \n","    e_input=[]\n","    for i in enc_inp.split():\n","        if token_perturbation.word_index.get(i) == None:\n","            e_input.append(0)\n","        else:\n","            e_input.append(token_perturbation.word_index.get(i))\n","    #e_input = [token_perturbation.word_index[i] for i in enc_inp.split(\" \")]\n","    e_input = tf.keras.preprocessing.sequence.pad_sequences([e_input], maxlen=16, padding='post')\n","    \n","    \n","    e_output, e_hidden, e_cell = encoder(e_input,0)\n","    \n","    d_hidden = e_hidden\n","    d_cell = e_cell                   #final encoder state is equal to initial decoder state\n","    \n","    #initial decoder input is start\n","    d_input = tf.expand_dims([token_correct.word_index['<start>']],0)\n","\n","    attention_weights = np.zeros((1,16), dtype='float32')\n","    attention_weights[:,0] = 1\n","\n","    for word in range(16):\n","        \n","        predicted, d_hidden, d_cell, attention_weights, context_vector = onestep(d_input, e_output, d_hidden, d_cell,\n","                                                                                 attention_weights)        \n","        \n","        #attention_weights = tf.reshape(attention_weights, (-1,))  #creating a 1d tensor attention weights to store them\n","        #attention_plot[word] = attention_weights.numpy()\n","        \n","        #making predictions\n","        predicted_word_index = tf.argmax(predicted[0]).numpy()  #it will give the highest probability word\n","      \n","\n","        #stopping when reaching \"<end>\"\n","        if token_correct.index_word[predicted_word_index] == '<end>':\n","            return translation #, attention_plot\n","        \n","        #appending the result with predicted words\n","        translation = translation + token_correct.index_word[predicted_word_index] + ' '\n","        \n","        # the predicted ID is fed back into the model\n","        d_input = tf.expand_dims([predicted_word_index], 0)\n","        \n","    return translation #, attention_plot"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'i have a pen '"]},"metadata":{},"execution_count":37}],"source":["inference_att('i have pen')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import math"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["def beamsearch(enc_inp, beam_width):\n","    \n","    start = [token_correct.word_index['<start>']]\n","\n","    sequences = [[start, 0]]\n","    e_input=[]\n","    for i in enc_inp.split():\n","        if token_perturbation.word_index.get(i) == None:\n","            e_input.append(0)\n","        else:\n","            e_input.append(token_perturbation.word_index.get(i))\n","\n","    e_input = tf.keras.preprocessing.sequence.pad_sequences([e_input], maxlen=16, padding='post')\n","\n","\n","    e_output, e_hidden, e_cell = encoder(e_input,0)\n","\n","    d_hidden = e_hidden\n","    d_cell = e_cell                   #final encoder state is equal to initial decoder state\n","\n","    #initial decoder input is start\n","    d_input = tf.expand_dims([token_correct.word_index['<start>']],0)\n","    attention_weights = np.zeros((1,16), dtype='float32')\n","    attention_weights[:,0] = 1\n","    \n","    #img_features = Xnet_Features[image]\n","    #img_features = encoder_model.predict(img_features)\n","    finished_seq = []\n","    \n","    for i in range(20):\n","        all_candidates = []\n","        new_seq = []\n","        for s in sequences:\n","\n","            #text_input = pad_sequences([s[0]], 155, padding='post')\n","            predictions, d_hidden, d_cell, attention_weights, context_vector = onestep(d_input, e_output,                                                                         d_hidden, d_cell, attention_weights)\n","            top_words = np.argsort(predictions[0])[-beam_width:]\n","            seq, score = s\n","            \n","            for t in top_words:\n","                candidates = [seq + [t], score - math.log(predictions[0][t])]\n","                all_candidates.append(candidates)\n","                \n","        sequences = sorted(all_candidates, key = lambda l: l[1])[:beam_width]\n","        # checks for 'endseq' in each seq in the beam\n","        count = 0\n","        for seq,score in sequences:\n","            if seq[len(seq)-1] == token_correct.word_index['<end>']:\n","                score = score/len(seq)   # normalized\n","                finished_seq.append([seq, score])\n","                count+=1\n","            else:\n","                new_seq.append([seq, score])\n","        beam_width -= count\n","        sequences = new_seq\n","        \n","        # if all the sequences reaches its end before 155 timesteps\n","        if not sequences:\n","            break\n","        else:\n","            continue\n","        \n","    sequences = finished_seq[-1] \n","    rep = sequences[0]\n","    score = sequences[1]\n","    temp = []\n","    rep.pop(0)\n","    for word in rep:\n","        if word != token_correct.word_index['<end>']:\n","            temp.append(token_correct.index_word[word])\n","        else:\n","            break    \n","    rep = ' '.join(e for e in temp)        \n","    \n","    return rep, score"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('we we to the', -2.3801649549686075)"]},"metadata":{},"execution_count":50}],"source":["beamsearch('we are going to hospital', 3)"]},{"source":["## Train"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["train = pickle.load(open('C:/Users/rpris/OneDrive/Desktop/Project_2/train-reg.pkl', 'rb'))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [10:19<00:00,  1.61it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            encoder_input  \\\n","80389      a key that is it that is what he talking about   \n","140069          than what do you want to stay with me for   \n","100549  in view of all circumstances commissioner has ...   \n","186633           what the status of the decryption effort   \n","98686      look at me i can not even fly out of an window   \n","192556              i thought they was carrying something   \n","27749   eric wanted to see the island and the dinosaur...   \n","130066  you should not believe what i say when i am wi...   \n","165992                          it me they wanted not you   \n","127474                      oh for chrissake she an actor   \n","\n","                                           correct_output  \\\n","80389   a key that is it that is what he was talking a...   \n","140069    then what do you want to stay with me for <end>   \n","100549  in view of all the circumstances the commissio...   \n","186633  what is the status of the decryption effort <end>   \n","98686   look at me i can not even fly out of a window ...   \n","192556          i thought he was carrying something <end>   \n","27749   eric wanted to see the island and the dinosaur...   \n","130066  you should not believe what i say when i am wi...   \n","165992                 it is me they wanted not you <end>   \n","127474            oh for chrissake she was an actor <end>   \n","\n","                                    beam_predicted_output  \n","80389   a key is that is that is what he is talking ab...  \n","140069             then what do you want to stay with me   \n","100549  in view of all the circumstances council has d...  \n","186633       what is the status of the decryption effort   \n","98686      look at me i can not even fly out of a window   \n","192556               i thought he was carrying something   \n","27749   see the island and the dinosaurs so ben found ...  \n","130066  you should not believe what i say when i am wi...  \n","165992                          it is me they wanted not   \n","127474                       oh for chrissake she was an   "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoder_input</th>\n      <th>correct_output</th>\n      <th>beam_predicted_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>80389</th>\n      <td>a key that is it that is what he talking about</td>\n      <td>a key that is it that is what he was talking a...</td>\n      <td>a key is that is that is what he is talking ab...</td>\n    </tr>\n    <tr>\n      <th>140069</th>\n      <td>than what do you want to stay with me for</td>\n      <td>then what do you want to stay with me for &lt;end&gt;</td>\n      <td>then what do you want to stay with me</td>\n    </tr>\n    <tr>\n      <th>100549</th>\n      <td>in view of all circumstances commissioner has ...</td>\n      <td>in view of all the circumstances the commissio...</td>\n      <td>in view of all the circumstances council has d...</td>\n    </tr>\n    <tr>\n      <th>186633</th>\n      <td>what the status of the decryption effort</td>\n      <td>what is the status of the decryption effort &lt;end&gt;</td>\n      <td>what is the status of the decryption effort</td>\n    </tr>\n    <tr>\n      <th>98686</th>\n      <td>look at me i can not even fly out of an window</td>\n      <td>look at me i can not even fly out of a window ...</td>\n      <td>look at me i can not even fly out of a window</td>\n    </tr>\n    <tr>\n      <th>192556</th>\n      <td>i thought they was carrying something</td>\n      <td>i thought he was carrying something &lt;end&gt;</td>\n      <td>i thought he was carrying something</td>\n    </tr>\n    <tr>\n      <th>27749</th>\n      <td>eric wanted to see the island and the dinosaur...</td>\n      <td>eric wanted to see the island and the dinosaur...</td>\n      <td>see the island and the dinosaurs so ben found ...</td>\n    </tr>\n    <tr>\n      <th>130066</th>\n      <td>you should not believe what i say when i am wi...</td>\n      <td>you should not believe what i say when i am wi...</td>\n      <td>you should not believe what i say when i am wi...</td>\n    </tr>\n    <tr>\n      <th>165992</th>\n      <td>it me they wanted not you</td>\n      <td>it is me they wanted not you &lt;end&gt;</td>\n      <td>it is me they wanted not</td>\n    </tr>\n    <tr>\n      <th>127474</th>\n      <td>oh for chrissake she an actor</td>\n      <td>oh for chrissake she was an actor &lt;end&gt;</td>\n      <td>oh for chrissake she was an</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":30}],"source":["sample_train = train.sample(1000)\n","result = []\n","for enc_inp,dec_inp,_ in tqdm(sample_train.values):\n","    pred = beam(enc_inp)\n","    result.append(pred)\n","sample_train['correct_output'] = sample_train['decoder_output']\n","sample_train['beam_predicted_output'] = result\n","sample_train = sample_train.drop(['decoder_input', 'decoder_output'], axis=1)\n","sample_train.head(10)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["import nltk.translate.bleu_score as bleu"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score of train dataset with beam-search is 0.9017522264103863\n"]}],"source":["train_bleu = []\n","for enc_inp,correct,pred in sample_train.values:\n","    \n","    correct = correct.split()[:-1]    #removing end\n","    pred = pred.split()\n","    \n","    if len(correct) == len(pred):\n","        train_bleu.append(bleu.sentence_bleu([correct],pred))\n","        \n","print(\"BLEU Score of train dataset with beam-search is\",sum(train_bleu)/len(train_bleu))"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [01:46<00:00,  9.42it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            encoder_input  \\\n","80389      a key that is it that is what he talking about   \n","140069          than what do you want to stay with me for   \n","100549  in view of all circumstances commissioner has ...   \n","186633           what the status of the decryption effort   \n","98686      look at me i can not even fly out of an window   \n","192556              i thought they was carrying something   \n","27749   eric wanted to see the island and the dinosaur...   \n","130066  you should not believe what i say when i am wi...   \n","165992                          it me they wanted not you   \n","127474                      oh for chrissake she an actor   \n","\n","                                           correct_output  \\\n","80389   a key that is it that is what he was talking a...   \n","140069    then what do you want to stay with me for <end>   \n","100549  in view of all the circumstances the commissio...   \n","186633  what is the status of the decryption effort <end>   \n","98686   look at me i can not even fly out of a window ...   \n","192556          i thought he was carrying something <end>   \n","27749   eric wanted to see the island and the dinosaur...   \n","130066  you should not believe what i say when i am wi...   \n","165992                 it is me they wanted not you <end>   \n","127474            oh for chrissake she was an actor <end>   \n","\n","                                    beam_predicted_output  \\\n","80389   a key is that is that is what he is talking ab...   \n","140069             then what do you want to stay with me    \n","100549  in view of all the circumstances council has d...   \n","186633       what is the status of the decryption effort    \n","98686      look at me i can not even fly out of a window    \n","192556               i thought he was carrying something    \n","27749   see the island and the dinosaurs so ben found ...   \n","130066  you should not believe what i say when i am wi...   \n","165992                          it is me they wanted not    \n","127474                       oh for chrissake she was an    \n","\n","                                  greedy_predicted_output  \n","80389   a key that is it that is what he is talking ab...  \n","140069         then what do you want to stay with me for   \n","100549  in view of all the circumstances the commissio...  \n","186633       what is the status of the decryption effort   \n","98686      look at me i can not even fly out of a window   \n","192556               i thought he was carrying something   \n","27749   see the island and the dinosaurs so ben found ...  \n","130066  you should not believe what i say when i am wi...  \n","165992                      it is me they wanted not you   \n","127474                       oh for chrissake she was an   "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoder_input</th>\n      <th>correct_output</th>\n      <th>beam_predicted_output</th>\n      <th>greedy_predicted_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>80389</th>\n      <td>a key that is it that is what he talking about</td>\n      <td>a key that is it that is what he was talking a...</td>\n      <td>a key is that is that is what he is talking ab...</td>\n      <td>a key that is it that is what he is talking ab...</td>\n    </tr>\n    <tr>\n      <th>140069</th>\n      <td>than what do you want to stay with me for</td>\n      <td>then what do you want to stay with me for &lt;end&gt;</td>\n      <td>then what do you want to stay with me</td>\n      <td>then what do you want to stay with me for</td>\n    </tr>\n    <tr>\n      <th>100549</th>\n      <td>in view of all circumstances commissioner has ...</td>\n      <td>in view of all the circumstances the commissio...</td>\n      <td>in view of all the circumstances council has d...</td>\n      <td>in view of all the circumstances the commissio...</td>\n    </tr>\n    <tr>\n      <th>186633</th>\n      <td>what the status of the decryption effort</td>\n      <td>what is the status of the decryption effort &lt;end&gt;</td>\n      <td>what is the status of the decryption effort</td>\n      <td>what is the status of the decryption effort</td>\n    </tr>\n    <tr>\n      <th>98686</th>\n      <td>look at me i can not even fly out of an window</td>\n      <td>look at me i can not even fly out of a window ...</td>\n      <td>look at me i can not even fly out of a window</td>\n      <td>look at me i can not even fly out of a window</td>\n    </tr>\n    <tr>\n      <th>192556</th>\n      <td>i thought they was carrying something</td>\n      <td>i thought he was carrying something &lt;end&gt;</td>\n      <td>i thought he was carrying something</td>\n      <td>i thought he was carrying something</td>\n    </tr>\n    <tr>\n      <th>27749</th>\n      <td>eric wanted to see the island and the dinosaur...</td>\n      <td>eric wanted to see the island and the dinosaur...</td>\n      <td>see the island and the dinosaurs so ben found ...</td>\n      <td>see the island and the dinosaurs so ben found ...</td>\n    </tr>\n    <tr>\n      <th>130066</th>\n      <td>you should not believe what i say when i am wi...</td>\n      <td>you should not believe what i say when i am wi...</td>\n      <td>you should not believe what i say when i am wi...</td>\n      <td>you should not believe what i say when i am wi...</td>\n    </tr>\n    <tr>\n      <th>165992</th>\n      <td>it me they wanted not you</td>\n      <td>it is me they wanted not you &lt;end&gt;</td>\n      <td>it is me they wanted not</td>\n      <td>it is me they wanted not you</td>\n    </tr>\n    <tr>\n      <th>127474</th>\n      <td>oh for chrissake she an actor</td>\n      <td>oh for chrissake she was an actor &lt;end&gt;</td>\n      <td>oh for chrissake she was an</td>\n      <td>oh for chrissake she was an</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":38}],"source":["result = []\n","for enc_inp,dec_inp,_ in tqdm(sample_train.values):\n","    pred = inference_att(enc_inp)\n","    result.append(pred)\n","\n","sample_train['greedy_predicted_output'] = result\n","sample_train.head(10)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score of train dataset with greedy-search is 0.9224930633097495\n"]}],"source":["train_bleu_gr = []\n","for enc_inp,correct,pred,gr in sample_train.values:\n","    \n","    correct = correct.split()[:-1]    #removing end\n","    gr = gr.split()\n","    \n","    if len(correct) == len(gr):\n","        train_bleu_gr.append(bleu.sentence_bleu([correct],gr))\n","        \n","print(\"BLEU Score of train dataset with greedy-search is\",sum(train_bleu_gr)/len(train_bleu_gr))"]},{"source":["## Validation"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["validation = pickle.load(open('C:/Users/rpris/OneDrive/Desktop/Project_2/validation-reg.pkl', 'rb'))"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [08:41<00:00,  1.92it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            encoder_input  \\\n","67940                  but it not worth more than fifteen   \n","109011  lecter there is no correlation in literature b...   \n","162359     because it sentimental tacky crap that why not   \n","201411  how come you all ai not sendin them to same sc...   \n","195977              barton i am afraid it not a good time   \n","132977                                  we waiting hubert   \n","11931       do you know what friend you have in jesus son   \n","190386  we not all hopped up on benzedrine orson i som...   \n","197686  tasting and enjoying life the only thing of va...   \n","205344                     someone trying to kill eleanor   \n","\n","                                           correct_output  \\\n","67940         but it is not worth more than fifteen <end>   \n","109011  lecter there is no correlation in the literatu...   \n","162359  because it is sentimental tacky crap that is w...   \n","201411  how come you all ai not sendin them to the sam...   \n","195977     barton i am afraid it is not a good time <end>   \n","132977                        we are waiting hubert <end>   \n","11931   do you know what a friend you have in jesus so...   \n","190386  we are not all hopped up on benzedrine orson i...   \n","197686  tasting and enjoying life is the only thing of...   \n","205344            someone is trying to kill eleanor <end>   \n","\n","                                    beam_predicted_output  \n","67940              but it is not worth more than fifteen   \n","109011  lecter there is no correlation in literature b...  \n","162359  because it is frightening shootin that crap is...  \n","201411     how come you all ai not thee them to the same   \n","195977          barton i am afraid it is not a good time   \n","132977                                    we are waiting   \n","11931   do you know what friend you have in the warren...  \n","190386  we not all hopped up filling on ganz i got eac...  \n","197686  tasting and enjoying the life the thing of val...  \n","205344                              someone is trying to   "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoder_input</th>\n      <th>correct_output</th>\n      <th>beam_predicted_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67940</th>\n      <td>but it not worth more than fifteen</td>\n      <td>but it is not worth more than fifteen &lt;end&gt;</td>\n      <td>but it is not worth more than fifteen</td>\n    </tr>\n    <tr>\n      <th>109011</th>\n      <td>lecter there is no correlation in literature b...</td>\n      <td>lecter there is no correlation in the literatu...</td>\n      <td>lecter there is no correlation in literature b...</td>\n    </tr>\n    <tr>\n      <th>162359</th>\n      <td>because it sentimental tacky crap that why not</td>\n      <td>because it is sentimental tacky crap that is w...</td>\n      <td>because it is frightening shootin that crap is...</td>\n    </tr>\n    <tr>\n      <th>201411</th>\n      <td>how come you all ai not sendin them to same sc...</td>\n      <td>how come you all ai not sendin them to the sam...</td>\n      <td>how come you all ai not thee them to the same</td>\n    </tr>\n    <tr>\n      <th>195977</th>\n      <td>barton i am afraid it not a good time</td>\n      <td>barton i am afraid it is not a good time &lt;end&gt;</td>\n      <td>barton i am afraid it is not a good time</td>\n    </tr>\n    <tr>\n      <th>132977</th>\n      <td>we waiting hubert</td>\n      <td>we are waiting hubert &lt;end&gt;</td>\n      <td>we are waiting</td>\n    </tr>\n    <tr>\n      <th>11931</th>\n      <td>do you know what friend you have in jesus son</td>\n      <td>do you know what a friend you have in jesus so...</td>\n      <td>do you know what friend you have in the warren...</td>\n    </tr>\n    <tr>\n      <th>190386</th>\n      <td>we not all hopped up on benzedrine orson i som...</td>\n      <td>we are not all hopped up on benzedrine orson i...</td>\n      <td>we not all hopped up filling on ganz i got eac...</td>\n    </tr>\n    <tr>\n      <th>197686</th>\n      <td>tasting and enjoying life the only thing of va...</td>\n      <td>tasting and enjoying life is the only thing of...</td>\n      <td>tasting and enjoying the life the thing of val...</td>\n    </tr>\n    <tr>\n      <th>205344</th>\n      <td>someone trying to kill eleanor</td>\n      <td>someone is trying to kill eleanor &lt;end&gt;</td>\n      <td>someone is trying to</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":42}],"source":["sample_validation = validation.sample(1000)\n","result = []\n","for enc_inp,dec_inp,_ in tqdm(sample_validation.values):\n","    pred = beam(enc_inp)\n","    result.append(pred)\n","sample_validation['correct_output'] = sample_validation['decoder_output']\n","sample_validation['beam_predicted_output'] = result\n","sample_validation = sample_validation.drop(['decoder_input', 'decoder_output'], axis=1)\n","sample_validation.head(10)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score of validation dataset with beam-search is 0.7387638566773894\n"]}],"source":["validation_bleu = []\n","for enc_inp,correct,pred in sample_validation.values:\n","    \n","    correct = correct.split()[:-1]    #removing end\n","    pred = pred.split()\n","\n","    if len(correct) == len(pred):\n","        validation_bleu.append(bleu.sentence_bleu([correct],pred))\n","        \n","print(\"BLEU Score of validation dataset with beam-search is\",sum(validation_bleu)/len(validation_bleu))"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [01:31<00:00, 10.97it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            encoder_input  \\\n","67940                  but it not worth more than fifteen   \n","109011  lecter there is no correlation in literature b...   \n","162359     because it sentimental tacky crap that why not   \n","201411  how come you all ai not sendin them to same sc...   \n","195977              barton i am afraid it not a good time   \n","132977                                  we waiting hubert   \n","11931       do you know what friend you have in jesus son   \n","190386  we not all hopped up on benzedrine orson i som...   \n","197686  tasting and enjoying life the only thing of va...   \n","205344                     someone trying to kill eleanor   \n","\n","                                           correct_output  \\\n","67940         but it is not worth more than fifteen <end>   \n","109011  lecter there is no correlation in the literatu...   \n","162359  because it is sentimental tacky crap that is w...   \n","201411  how come you all ai not sendin them to the sam...   \n","195977     barton i am afraid it is not a good time <end>   \n","132977                        we are waiting hubert <end>   \n","11931   do you know what a friend you have in jesus so...   \n","190386  we are not all hopped up on benzedrine orson i...   \n","197686  tasting and enjoying life is the only thing of...   \n","205344            someone is trying to kill eleanor <end>   \n","\n","                                    beam_predicted_output  \\\n","67940              but it is not worth more than fifteen    \n","109011  lecter there is no correlation in literature b...   \n","162359  because it is frightening shootin that crap is...   \n","201411     how come you all ai not thee them to the same    \n","195977          barton i am afraid it is not a good time    \n","132977                                    we are waiting    \n","11931   do you know what friend you have in the warren...   \n","190386  we not all hopped up filling on ganz i got eac...   \n","197686  tasting and enjoying the life the thing of val...   \n","205344                              someone is trying to    \n","\n","                                  greedy_predicted_output  \n","67940              but it is not worth more than fifteen   \n","109011  lecter there is no correlation in the literatu...  \n","162359  because it is frightening shootin that crap is...  \n","201411  how come you all ai not thee them to the same ...  \n","195977          barton i am afraid it is not a good time   \n","132977                                   we were waiting   \n","11931   do you know what friend you have in the jesus ...  \n","190386  all not all the up on throw ahold i some of us...  \n","197686  tasting and enjoying life the only thing of va...  \n","205344                         someone is trying to kill   "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoder_input</th>\n      <th>correct_output</th>\n      <th>beam_predicted_output</th>\n      <th>greedy_predicted_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67940</th>\n      <td>but it not worth more than fifteen</td>\n      <td>but it is not worth more than fifteen &lt;end&gt;</td>\n      <td>but it is not worth more than fifteen</td>\n      <td>but it is not worth more than fifteen</td>\n    </tr>\n    <tr>\n      <th>109011</th>\n      <td>lecter there is no correlation in literature b...</td>\n      <td>lecter there is no correlation in the literatu...</td>\n      <td>lecter there is no correlation in literature b...</td>\n      <td>lecter there is no correlation in the literatu...</td>\n    </tr>\n    <tr>\n      <th>162359</th>\n      <td>because it sentimental tacky crap that why not</td>\n      <td>because it is sentimental tacky crap that is w...</td>\n      <td>because it is frightening shootin that crap is...</td>\n      <td>because it is frightening shootin that crap is...</td>\n    </tr>\n    <tr>\n      <th>201411</th>\n      <td>how come you all ai not sendin them to same sc...</td>\n      <td>how come you all ai not sendin them to the sam...</td>\n      <td>how come you all ai not thee them to the same</td>\n      <td>how come you all ai not thee them to the same ...</td>\n    </tr>\n    <tr>\n      <th>195977</th>\n      <td>barton i am afraid it not a good time</td>\n      <td>barton i am afraid it is not a good time &lt;end&gt;</td>\n      <td>barton i am afraid it is not a good time</td>\n      <td>barton i am afraid it is not a good time</td>\n    </tr>\n    <tr>\n      <th>132977</th>\n      <td>we waiting hubert</td>\n      <td>we are waiting hubert &lt;end&gt;</td>\n      <td>we are waiting</td>\n      <td>we were waiting</td>\n    </tr>\n    <tr>\n      <th>11931</th>\n      <td>do you know what friend you have in jesus son</td>\n      <td>do you know what a friend you have in jesus so...</td>\n      <td>do you know what friend you have in the warren...</td>\n      <td>do you know what friend you have in the jesus ...</td>\n    </tr>\n    <tr>\n      <th>190386</th>\n      <td>we not all hopped up on benzedrine orson i som...</td>\n      <td>we are not all hopped up on benzedrine orson i...</td>\n      <td>we not all hopped up filling on ganz i got eac...</td>\n      <td>all not all the up on throw ahold i some of us...</td>\n    </tr>\n    <tr>\n      <th>197686</th>\n      <td>tasting and enjoying life the only thing of va...</td>\n      <td>tasting and enjoying life is the only thing of...</td>\n      <td>tasting and enjoying the life the thing of val...</td>\n      <td>tasting and enjoying life the only thing of va...</td>\n    </tr>\n    <tr>\n      <th>205344</th>\n      <td>someone trying to kill eleanor</td>\n      <td>someone is trying to kill eleanor &lt;end&gt;</td>\n      <td>someone is trying to</td>\n      <td>someone is trying to kill</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":46}],"source":["result = []\n","for enc_inp,dec_inp,_ in tqdm(sample_validation.values):\n","    gr = inference_att(enc_inp)\n","    result.append(gr)\n","\n","sample_validation['greedy_predicted_output'] = result\n","\n","sample_validation.head(10)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score of validation dataset with greedy-search is 0.7565663868271315\n"]}],"source":["validation_bleu_gr = []\n","for enc_inp,correct,pred,gr in sample_validation.values:\n","    \n","    correct = correct.split()[:-1]    #removing end\n","    gr = gr.split()\n","\n","    if len(correct) == len(gr):\n","        validation_bleu_gr.append(bleu.sentence_bleu([correct],gr))\n","        \n","print(\"BLEU Score of validation dataset with greedy-search is\",sum(validation_bleu_gr)/len(validation_bleu_gr))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}